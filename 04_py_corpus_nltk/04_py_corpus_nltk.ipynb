{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Korpusverarbeitung mit Python und NLTK\n",
    "\n",
    "- Verarbeiten von Korpusdateien mit Python (`open()`, `split()`, `glob()`) \n",
    "- Frequenzliste mit Python\n",
    "- Formate verschiedener Korpustypen (z.B. POS-annotierte Korpora als Wort-POS-Tuppellisten)\n",
    "\n",
    "- NLTK Korpusreader: z.B. `nltk.PlaintextCorpusReader()`\n",
    "- NLTK Korpusmethoden: `nltk.words()`, `nltk.Text()`\n",
    "- NLTK Ressourcen: Korpora, Stopwortlisten\n",
    "- NLTK Frequenzlisten: `nltk.FreqDist()`, `nltk.ConditionalFreqDist()`\n",
    "- NLTK Konkordanzen: `nltk.concordance()`\n",
    "- NLTK Kollokationen: `nltk.collocations()`\n",
    "\n",
    "\n",
    "\n",
    "- Literatur: Kapitel 1-3 in https://www.nltk.org/book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Korpusverarbeitung mit Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### open / read\n",
    "\n",
    "- Öffnen und Einlesen von Korpus-Textdateien\n",
    "- `with open` erübrigt schließen des Dateihandles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call me Ishmael. Some years ago—never mind how long precisely—having little or no money in my purse, and nothing particular to interest me on shore, I thought I would sail about a little and see the watery part of the world.\n"
     ]
    }
   ],
   "source": [
    "with open('sample_texts/sample_text.txt') as f:\n",
    "    sample_text=f.read()\n",
    "print(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split / re.split / re.findall\n",
    "\n",
    "- Zur Tokenisierung wird der Text in Wörter und ggf auch Satzzeichen (punctuation) gesplittet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Call', 'me', 'Ishmael.', 'Some', 'years', 'ago—never', 'mind', 'how', 'long', 'precisely—having', 'little', 'or', 'no', 'money', 'in', 'my', 'purse,', 'and', 'nothing', 'particular', 'to', 'interest', 'me', 'on', 'shore,', 'I', 'thought', 'I', 'would', 'sail', 'about', 'a', 'little', 'and', 'see', 'the', 'watery', 'part', 'of', 'the', 'world.']\n"
     ]
    }
   ],
   "source": [
    "sample_text_tokens = sample_text.split()\n",
    "print(sample_text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Call', 'me', 'Ishmael', 'Some', 'years', 'ago', 'never', 'mind', 'how', 'long', 'precisely', 'having', 'little', 'or', 'no', 'money', 'in', 'my', 'purse', 'and', 'nothing', 'particular', 'to', 'interest', 'me', 'on', 'shore', 'I', 'thought', 'I', 'would', 'sail', 'about', 'a', 'little', 'and', 'see', 'the', 'watery', 'part', 'of', 'the', 'world']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "sample_text_tokens = list(filter(None, re.split('[^\\w+]',sample_text)))\n",
    "print(sample_text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Call', 'me', 'Ishmael', 'Some', 'years', 'ago', 'never', 'mind', 'how', 'long', 'precisely', 'having', 'little', 'or', 'no', 'money', 'in', 'my', 'purse', 'and', 'nothing', 'particular', 'to', 'interest', 'me', 'on', 'shore', 'I', 'thought', 'I', 'would', 'sail', 'about', 'a', 'little', 'and', 'see', 'the', 'watery', 'part', 'of', 'the', 'world']\n"
     ]
    }
   ],
   "source": [
    "sample_text_tokens = re.findall('[\\w]+',sample_text)\n",
    "print(sample_text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Call', 'me', 'Ishmael', '.', 'Some', 'years', 'ago', '—', 'never', 'mind', 'how', 'long', 'precisely', '—', 'having', 'little', 'or', 'no', 'money', 'in', 'my', 'purse', ',', 'and', 'nothing', 'particular', 'to', 'interest', 'me', 'on', 'shore', ',', 'I', 'thought', 'I', 'would', 'sail', 'about', 'a', 'little', 'and', 'see', 'the', 'watery', 'part', 'of', 'the', 'world', '.']\n"
     ]
    }
   ],
   "source": [
    "sample_text_tokens = re.findall('\\w+|[^\\w\\s]+',sample_text) ##entspricht nltk.wordpunct_tokenize\n",
    "print(sample_text_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zip\n",
    "\n",
    "- zip aggregiert iterierbare Elemente in Tupel\n",
    "- Verwendung zur Generierung von N-grammen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Call', 'me', 'Ishmael', '.', 'Some', 'years', 'ago']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = sample_text_tokens[:7]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Call', 'Call'), ('me', 'me'), ('Ishmael', 'Ishmael'), ('.', '.'), ('Some', 'Some'), ('years', 'years'), ('ago', 'ago')]\n"
     ]
    }
   ],
   "source": [
    "result = zip(tokens, tokens)\n",
    "print(list(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Call', 'me', 'Ishmael'), ('me', 'Ishmael', '.'), ('Ishmael', '.', 'Some'), ('.', 'Some', 'years'), ('Some', 'years', 'ago')]\n"
     ]
    }
   ],
   "source": [
    "result = zip(tokens, tokens[1:], tokens[2:])\n",
    "print(list(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### glob\n",
    "\n",
    "- ermöglicht ähnlich wie Globs auf der bash das Iterieren über Verzeichnisse, etwa zum Einlesen der Dateien in einem Korpus-Verzeichnis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_texts/sample_text.txt', 'sample_texts/sample_text2.txt']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "print(glob.glob('sample_texts/*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Call', 'me', 'Ishmael', '', 'Some', 'years', 'ago', 'never', 'mind', 'how', 'long', 'precisely', 'having', 'little', 'or', 'no', 'money', 'in', 'my', 'purse', '', 'and', 'nothing', 'particular', 'to', 'interest', 'me', 'on', 'shore', '', 'I', 'thought', 'I', 'would', 'sail', 'about', 'a', 'little', 'and', 'see', 'the', 'watery', 'part', 'of', 'the', 'world', ''], ['There', 'now', 'is', 'your', 'insular', 'city', 'of', 'the', 'Manhattoes', '', 'belted', 'round', 'by', 'wharves', 'as', 'Indian', 'isles', 'by', 'coral', 'reefs', 'commerce', 'surrounds', 'it', 'with', 'her', 'surf', '', 'Right', 'and', 'left', '', 'the', 'streets', 'take', 'you', 'waterward', '', 'Its', 'extreme', 'downtown', 'is', 'the', 'battery', '', 'where', 'that', 'noble', 'mole', 'is', 'washed', 'by', 'waves', '', 'and', 'cooled', 'by', 'breezes', '', 'which', 'a', 'few', 'hours', 'previous', 'were', 'out', 'of', 'sight', 'of', 'land', '', 'Look', 'at', 'the', 'crowds', 'of', 'water', 'gazers', 'there', '']]\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for filename in glob.glob('sample_texts/*.txt'):\n",
    "    f=open(filename,'r',encoding='utf8')\n",
    "    text=f.read()\n",
    "    f.close()\n",
    "    tokens = re.split('[^\\w+]',text)\n",
    "    #corpus.extend(tokens)\n",
    "    corpus.append(tokens) #list of wordlists per document\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erzeugung einer Korpus-Wortliste aus der Liste von Dokumenten-Wortlisten (*flatten list*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Call', 'me', 'Ishmael', '', 'Some', 'years', 'ago', 'never', 'mind', 'how', 'long', 'precisely', 'having', 'little', 'or', 'no', 'money', 'in', 'my', 'purse', '', 'and', 'nothing', 'particular', 'to', 'interest', 'me', 'on', 'shore', '', 'I', 'thought', 'I', 'would', 'sail', 'about', 'a', 'little', 'and', 'see', 'the', 'watery', 'part', 'of', 'the', 'world', '', 'There', 'now', 'is', 'your', 'insular', 'city', 'of', 'the', 'Manhattoes', '', 'belted', 'round', 'by', 'wharves', 'as', 'Indian', 'isles', 'by', 'coral', 'reefs', 'commerce', 'surrounds', 'it', 'with', 'her', 'surf', '', 'Right', 'and', 'left', '', 'the', 'streets', 'take', 'you', 'waterward', '', 'Its', 'extreme', 'downtown', 'is', 'the', 'battery', '', 'where', 'that', 'noble', 'mole', 'is', 'washed', 'by', 'waves', '', 'and', 'cooled', 'by', 'breezes', '', 'which', 'a', 'few', 'hours', 'previous', 'were', 'out', 'of', 'sight', 'of', 'land', '', 'Look', 'at', 'the', 'crowds', 'of', 'water', 'gazers', 'there', '']\n"
     ]
    }
   ],
   "source": [
    "corpus_words = [word for document in corpus for word in document]\n",
    "print(corpus_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erzeugung einer Frequenzliste in Python\n",
    "\n",
    "\n",
    "- Frequenzlisten werden in Python üblicherweise als Dictionaries repräsentiert\n",
    "- Verschiedene Varianten zur Berechnung mit Python sind möglich (z.B. mit `if-else`, `try-except`, `dictionary comprehension`)\n",
    "- in den Übungsaufgaben werden weitere Varianten verwendet und deren Performance über Efficiency Tests verglichen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Call': 1, 'me': 2, 'Ishmael': 1, '': 13, 'Some': 1, 'years': 1, 'ago': 1, 'never': 1, 'mind': 1, 'how': 1, 'long': 1, 'precisely': 1, 'having': 1, 'little': 2, 'or': 1, 'no': 1, 'money': 1, 'in': 1, 'my': 1, 'purse': 1, 'and': 4, 'nothing': 1, 'particular': 1, 'to': 1, 'interest': 1, 'on': 1, 'shore': 1, 'I': 2, 'thought': 1, 'would': 1, 'sail': 1, 'about': 1, 'a': 2, 'see': 1, 'the': 6, 'watery': 1, 'part': 1, 'of': 5, 'world': 1, 'There': 1, 'now': 1, 'is': 3, 'your': 1, 'insular': 1, 'city': 1, 'Manhattoes': 1, 'belted': 1, 'round': 1, 'by': 4, 'wharves': 1, 'as': 1, 'Indian': 1, 'isles': 1, 'coral': 1, 'reefs': 1, 'commerce': 1, 'surrounds': 1, 'it': 1, 'with': 1, 'her': 1, 'surf': 1, 'Right': 1, 'left': 1, 'streets': 1, 'take': 1, 'you': 1, 'waterward': 1, 'Its': 1, 'extreme': 1, 'downtown': 1, 'battery': 1, 'where': 1, 'that': 1, 'noble': 1, 'mole': 1, 'washed': 1, 'waves': 1, 'cooled': 1, 'breezes': 1, 'which': 1, 'few': 1, 'hours': 1, 'previous': 1, 'were': 1, 'out': 1, 'sight': 1, 'land': 1, 'Look': 1, 'at': 1, 'crowds': 1, 'water': 1, 'gazers': 1, 'there': 1}\n"
     ]
    }
   ],
   "source": [
    "counts = {}\n",
    "for t in corpus_words:\n",
    "    if t not in counts: counts[t] = 1\n",
    "    else: counts[t] += 1\n",
    "\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. NLTK Grundlagen Korpusverabreitung\n",
    "\n",
    "- die NLTK Library (*Natural Language Toolkit*) ist eine open source Plattform zur Verarbeitung von Sprachdaten\n",
    "- zum Funktionsumfang gehören: Tokenisierung, Stemming, Tagging, Parsing, Semantic reasoning, Klassifikation\n",
    "- sie bietet auch Zugriff auf eine Vielzahl an Ressourcen an, insbesondere verschiedene Korpora\n",
    "\n",
    "- NLTK wurde ursprünglich als Tool für den CL-Unterricht entwickelt\n",
    "- es gibt einen *hands-on guide (NLTK book)*: https://www.nltk.org/book/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  nltk.word_tokenize\n",
    "\n",
    "- der Default-NLTK-Tokenizer ist `word_tokenize`\n",
    "- primär für Englisch (Abkürzungen etc.)\n",
    "- daneben gibt es weitere Tokenizer:\n",
    "    - `wordpunct_tokenize()`, entspricht `re.findall(r'\\w+|[^\\w\\s]+', text)`\n",
    "    - `regexp_tokenize()`, erlaubt die Definition eigener Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Call', 'me', 'Ishmael', '.', 'Some', 'years', 'ago—never', 'mind', 'how', 'long', 'precisely—having', 'little', 'or', 'no', 'money', 'in', 'my', 'purse', ',', 'and', 'nothing', 'particular', 'to', 'interest', 'me', 'on', 'shore', ',', 'I', 'thought', 'I', 'would', 'sail', 'about', 'a', 'little', 'and', 'see', 'the', 'watery', 'part', 'of', 'the', 'world', '.']\n"
     ]
    }
   ],
   "source": [
    "sample_text_tokens = nltk.word_tokenize(sample_text)\n",
    "print(sample_text_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.sent_tokenize\n",
    "\n",
    "- führt eine Satzsegmentierung aus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Call me Ishmael.', 'Some years ago—never mind how long precisely—having little or no money in my purse, and nothing particular to interest me on shore, I thought I would sail about a little and see the watery part of the world.']\n"
     ]
    }
   ],
   "source": [
    "sample_text_sents = nltk.sent_tokenize(sample_text)\n",
    "print(sample_text_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Call', 'me', 'Ishmael', '.'], ['Some', 'years', 'ago—never', 'mind', 'how', 'long', 'precisely—having', 'little', 'or', 'no', 'money', 'in', 'my', 'purse', ',', 'and', 'nothing', 'particular', 'to', 'interest', 'me', 'on', 'shore', ',', 'I', 'thought', 'I', 'would', 'sail', 'about', 'a', 'little', 'and', 'see', 'the', 'watery', 'part', 'of', 'the', 'world', '.']]\n"
     ]
    }
   ],
   "source": [
    "sample_text_sents_tokens = [nltk.word_tokenize(sent) for sent in sample_text_sents] \n",
    "print(sample_text_sents_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### NLTK-Korpusreader\n",
    "\n",
    "- NLTK bietet verschiedene Korpus-Reader an, die Korpora direkt in die entsprechende Korpusformate/objekte einlesen: https://www.nltk.org/howto/corpus.html#corpus-readers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auflistung von Korpusreader-Methoden und deren Output-Typen:\n",
    "\n",
    "- words(): list of str\n",
    "- sents(): list of (list of str)\n",
    "- paras(): list of (list of (list of str))\n",
    "- tagged_words(): list of (str,str) tuple\n",
    "- tagged_sents(): list of (list of (str,str))\n",
    "- tagged_paras(): list of (list of (list of (str,str)))\n",
    "- chunked_sents(): list of (Tree w/ (str,str) leaves)\n",
    "- parsed_sents(): list of (Tree with str leaves)\n",
    "- parsed_paras(): list of (list of (Tree with str leaves))\n",
    "- xml(): A single xml ElementTree\n",
    "- raw(): unprocessed corpus contents\n",
    "\n",
    "https://github.com/nltk/nltk/blob/develop/nltk/corpus/reader/__init__.py#L32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.PlaintextCorpusReader\n",
    "\n",
    "\n",
    "- im einfachsten Fall liegen Korpora als Menge unannotierter Texte vorPlaintextCorpusReader \n",
    "- PlaintextCorpusReader ermöglicht das Einlesen eines reinen Text-Korpus aus einem Verzeichnis\n",
    "- Ergebnis ist ein entsprechendes Korpus-Objekt, für das verschiedene Methoden zur Verfügung stehen\n",
    "- insbesondere etwa die `words()`-Methode, die das Korpus als **Token-Liste** repräsentiert ausgibt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.corpus.reader.plaintext.PlaintextCorpusReader"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\n",
    "\n",
    "# RegEx or list of file names\n",
    "files = \".*\\.txt\"\n",
    "my_corpus = PlaintextCorpusReader(\"sample_texts\", files)\n",
    "type(my_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.words\n",
    "- mit der `nltk.words()`-Methoden wird das gesamte Korpus als Wortliste ausgegeben\n",
    "- eine Einschränkung auf bestimmte Dokumente ist über die Angabe als optionaler Parameter möglich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Call', 'me', 'Ishmael', '.', 'Some', 'years', 'ago', ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_corpus.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There', 'now', 'is', 'your', 'insular', 'city', 'of', ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_corpus.words('sample_text2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.sents\n",
    "\n",
    "- gibt satzsegmentierte Tokenlisten aus (sent_tokenize + word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Call', 'me', 'Ishmael', '.'], ['Some', 'years', 'ago', '—', 'never', 'mind', 'how', 'long', 'precisely', '—', 'having', 'little', 'or', 'no', 'money', 'in', 'my', 'purse', ',', 'and', 'nothing', 'particular', 'to', 'interest', 'me', 'on', 'shore', ',', 'I', 'thought', 'I', 'would', 'sail', 'about', 'a', 'little', 'and', 'see', 'the', 'watery', 'part', 'of', 'the', 'world', '.'], ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_corpus.sents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.Text\n",
    "\n",
    "- ist ein Wrapper um Token-Sequenzen: https://www.nltk.org/api/nltk.text.html#nltk.text.Text\n",
    "- erlaubt die Anwendung grundlegender Korpusmethoden zur initialen Textexploration (über die interaktive Konsole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Call me Ishmael . Some years ago —...>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_corpus_text = nltk.Text(my_corpus.words())\n",
    "my_corpus_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Call', 'me', 'Ishmael', '.', 'Some', 'years', 'ago', '—', 'never']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_corpus_text[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.text.Text"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(my_corpus_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.Text.count\n",
    "\n",
    "- zählt, wie oft ein Wort im Text vorkommt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_corpus_text.count('is')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.Text.index\n",
    "\n",
    "- sucht den Index des ersten Vorkommens des Worts im Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_corpus_text.index('is')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.Text.concordance\n",
    "- gibt eine Konkordanz (KWIC=Keyword in Context) für ein Wort mit dem angegebenen Kontextfenster aus\n",
    "- Wortabgleich ist nicht case-sensitiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 3 of 3 matches:\n",
      " watery part of the world . There now is your insular city of the Manhattoes ,\n",
      " you waterward . Its extreme downtown is the battery , where that noble mole i\n",
      "s the battery , where that noble mole is washed by waves , and cooled by breez\n"
     ]
    }
   ],
   "source": [
    "my_corpus_text.concordance('is')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.Text.findall\n",
    "\n",
    "- findet Instanzen des regulären Ausdrucks im Text\n",
    "- das RegExp-Muster, um eine einzelnes Token zu finden, muss in spitze Klammern eingeschlossen werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There now is\n"
     ]
    }
   ],
   "source": [
    "my_corpus_text.findall('<[Tt]here><.*><is>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.Text.vocab\n",
    "\n",
    "- gibt die Häufigkeitsverteilung der Token im Korpus zurück"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Call': 1,\n",
       " 'me': 2,\n",
       " 'Ishmael': 1,\n",
       " '.': 6,\n",
       " 'Some': 1,\n",
       " 'years': 1,\n",
       " 'ago': 1,\n",
       " '—': 3,\n",
       " 'never': 1,\n",
       " 'mind': 1}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = my_corpus_text.vocab()\n",
    "dict(list(vocabulary.items())[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.probability.FreqDist"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vocabulary) #entspricht FreqDist auf Tokens, s.u."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Call': 1,\n",
       " 'me': 2,\n",
       " 'Ishmael': 1,\n",
       " '.': 6,\n",
       " 'Some': 1,\n",
       " 'years': 1,\n",
       " 'ago': 1,\n",
       " '—': 3,\n",
       " 'never': 1,\n",
       " 'mind': 1}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "dict(list(FreqDist(my_corpus.words()).items())[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### TaggedCorpusReader\n",
    "\n",
    "- Reader für POS-annotierte Korpora im Format `word/POS`\n",
    "- Repräsentaion als **Tupelliste** über entsprechende Methoden: `(word, POS)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File IDs: ['sample_text2_pos.txt', 'sample_text_pos.txt']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import TaggedCorpusReader\n",
    "\n",
    "corpus_root = 'sample_texts_pos_tagged'\n",
    "corpus = TaggedCorpusReader(corpus_root, r'.*\\.txt')\n",
    "print(\"File IDs:\", corpus.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Call/VB me/PRP Ishmael/NNP ./.\\nSome/DT years/NNS ago/RB —/:\\nnever/RB mind/VB how/WRB long/JJ precisely/RB —/: \\nhaving/VBG little/JJ or/CC no/DT money/NN in/IN my/PRP$ purse/NN ,/,\\nand/CC nothing/NN particular/JJ to/TO interest/VB me/PRP on/IN shore/NN ,/,\\nI/PRP thought/VBD I/PRP would/MD sail/VB about/RB a/DT little/JJ and/CC see/VB the/DT watery/JJ part/NN of/IN the/DT world/NN ./.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_id = 'sample_text_pos.txt'\n",
    "corpus.raw(file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.tagged_words\n",
    "\n",
    "- Ausgabe der Token-POS-Tupel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Call', 'VB'), ('me', 'PRP'), ('Ishmael', 'NNP'), ...]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_id = 'sample_text_pos.txt'\n",
    "corpus.tagged_words(file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.tagged_sentences\n",
    "\n",
    "- satzweise Ausgabe der Token-POS-Tupel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Call', 'VB'), ('me', 'PRP'), ('Ishmael', 'NNP'), ('.', '.')]\n",
      "[('Some', 'DT'), ('years', 'NNS'), ('ago', 'RB'), ('—', ':')]\n",
      "[('never', 'RB'), ('mind', 'VB'), ('how', 'WRB'), ('long', 'JJ'), ('precisely', 'RB'), ('—', ':')]\n"
     ]
    }
   ],
   "source": [
    "file_id = 'sample_text_pos.txt'\n",
    "tagged_sentences = corpus.tagged_sents(file_id)\n",
    "for sentence in tagged_sentences[:3]:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Korpora und lexikalische Ressourcen in NLTK\n",
    "\n",
    "- NLTK stellt verschiedene Korpusressourcen zur Verfügung, die eigene Korpusreader haben\n",
    "- die bekannten Methoden (`words` etc.) können dann angewendet werden\n",
    "- die Korpora können auch Metadaten enthalten (s.u. Genres in Brown Korpus)\n",
    "- außerdem gibt es Stopwortlisten für verschiedene Sprachen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sense', 'and', 'Sensibility', 'by', 'Jane', 'Austen', '1811', ']', 'CHAPTER', '1', 'The', 'family', 'of', 'Dashwood', 'had', 'long', 'been', 'settled', 'in']\n"
     ]
    }
   ],
   "source": [
    "#Beispiel\n",
    "text = nltk.corpus.gutenberg.words('austen-sense.txt')\n",
    "print(text[1:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.download\n",
    "\n",
    "- ermöglicht den Download verschiedener Ressourcen\n",
    "- die \"book\"-Auswahl enthält die im NLTK-Book verwendeten Korpora und weitere Ressourcen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()\n",
    "#nltk.download('book')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.corpus\n",
    "\n",
    "- die spezialisierten Korpusreader für die NLTK-Korpora können über nltk.corpus geladen bzw. importiert werden\n",
    "\n",
    "Hier wird beispielsweise das Brown-Korpus (erstes 1-Million-Token-Korpus, POS-annotiert) geladen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#oder:\n",
    "brown = nltk.corpus.brown\n",
    "brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'AT'), ('Fulton', 'NP-TL'), ...]\n"
     ]
    }
   ],
   "source": [
    "print(brown.tagged_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DET'), ('Fulton', 'NOUN'), ...]\n"
     ]
    }
   ],
   "source": [
    "print(brown.tagged_words(tagset='universal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwort-Listen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- eine Stopwortliste enthält Wörter, die in der Verarbeitung der Korpusdaten herausgefiltert / nicht berücksichtigt werden (*negative dictionary*)\n",
    "- die Spezifik einer solchen Liste hängt vom Zweck ab, üblicherweise werden Funktionswörter herausgefiltert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "stop[0:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Korpus-Statistik mit NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.FreqDist\n",
    "\n",
    "- FreqDist (Frequency Distribution) ermöglicht die Berechnung von Frequenzlisten\n",
    "- repräsentiert als Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Brown-Korpus laden\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 62713, ',': 58334, '.': 49346, 'of': 36080, 'and': 27915, 'to': 25732, 'a': 21881, 'in': 19536, 'that': 10237, 'is': 10011, ...})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "fd = FreqDist(brown.words())\n",
    "fd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.FreqDist.most_common\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 62713),\n",
       " (',', 58334),\n",
       " ('.', 49346),\n",
       " ('of', 36080),\n",
       " ('and', 27915),\n",
       " ('to', 25732),\n",
       " ('a', 21881),\n",
       " ('in', 19536),\n",
       " ('that', 10237),\n",
       " ('is', 10011)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "fd.plot(35, cumulative=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.ConditionalFreqDist\n",
    "\n",
    "-  berechnet Häufigkeitsverteilungen für Subsets, differenziert nach spezifischen Bedingungen (Conditional Frequency Lists)\n",
    "\n",
    "\n",
    "Hier etwa differenziert nach Genre im Brown-Korpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ConditionalFreqDist\n",
    "import re\n",
    "\n",
    "cfd_genre = ConditionalFreqDist(\n",
    "    (genre, word)\n",
    "    for genre in brown.categories()\n",
    "    for word in brown.words(categories=genre) if (word.lower() not in stop and not re.match(r\"[^\\w]\", word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 330),\n",
       " ('would', 244),\n",
       " ('could', 193),\n",
       " ('like', 185),\n",
       " ('one', 166),\n",
       " ('back', 126),\n",
       " ('thought', 105),\n",
       " ('little', 99),\n",
       " ('time', 93),\n",
       " ('get', 92)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd_genre['romance'].most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('year', 183),\n",
       " ('States', 162),\n",
       " ('United', 155),\n",
       " ('may', 153),\n",
       " ('would', 120),\n",
       " ('made', 118),\n",
       " ('development', 112),\n",
       " ('one', 111),\n",
       " ('1', 107),\n",
       " ('years', 106)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd_genre['government'].most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konkordanzen und Kontexte\n",
    "\n",
    "- wie bereits oben gesehen ermöglicht NLTK die Ausgabe von Konkordanzen\n",
    "- Konkordanzen sind Trefferlisten mit Kontext (KWIC = Key Word in Context)\n",
    "- Konkordanzen sind einen zentrale Methode in der Korpuslinguistik\n",
    "\n",
    "\n",
    "- ebenso bietet NLTK Methoden an, um Wörter in ähnlichen Kontexten bzw. geteilte Kontexte zu finden\n",
    "\n",
    "\n",
    "Im folgenden Beispiel wir das NLTK Book Example Corpus geladen und der erste Text (Moby Dick) für die Berechnungen verwendet: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "#Loading NLTK Book Example Corpus\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 11 of 11 matches:\n",
      "ong the former , one was of a most monstrous size . ... This came towards us , \n",
      "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
      "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
      "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
      "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
      "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
      "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
      "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
      "ere to enter upon those still more monstrous stories of them which are to be fo\n",
      "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
      "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"
     ]
    }
   ],
   "source": [
    "text1.concordance(\"monstrous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.similar\n",
    "\n",
    "- berechnet ähnliche Wörter (mit geteilten Kontexten):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true contemptible christian abundant few part mean careful puzzled\n",
      "mystifying passing curious loving wise doleful gamesome singular\n",
      "delightfully perilous fearless\n"
     ]
    }
   ],
   "source": [
    "text1.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.common_contexts\n",
    "\n",
    "- berechnet geteilte Kontexte für Wörter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the_pictures\n"
     ]
    }
   ],
   "source": [
    "text1.common_contexts([\"monstrous\", \"true\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kollokationen\n",
    "\n",
    "- NLTK besitzt Methoden um häufig auftretende n-Gramme (Sequenzen benachbarter Wörter) zu finden\n",
    "- am häufigsten werden Bigramme (Auftreten zweier Wörter) untersucht\n",
    "- es gibt neben der simplen Häufigkeit des Auftretens verschiedene [Assoziationsmaße](https://www.nltk.org/howto/collocations.html#association-measures), die berechnen ob ein Bigramm häufiger als erwartet auftritt\n",
    "  - z.B. **Pointwise Mutual Information**: https://medium.com/dataseries/understanding-pointwise-mutual-information-in-nlp-e4ef75ecb57a\n",
    "\n",
    "\n",
    "https://www.nltk.org/howto/collocations.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Call', 'me'), ('me', 'Ishmael'), ('Ishmael', '.')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import bigrams\n",
    "list(bigrams(['Call', 'me', 'Ishmael', '.']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nlkt.collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sperm Whale; Moby Dick; White Whale; old man; Captain Ahab; sperm\n",
      "whale; Right Whale; Captain Peleg; New Bedford; Cape Horn; cried Ahab;\n",
      "years ago; lower jaw; never mind; Father Mapple; cried Stubb; chief\n",
      "mate; white whale; ivory leg; one hand\n"
     ]
    }
   ],
   "source": [
    "text1.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.collocations.BigramAssocMeasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.BigramCollocationFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = BigramCollocationFinder.from_words(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Moby', 'Dick'),\n",
       " ('Sperm', 'Whale'),\n",
       " ('White', 'Whale'),\n",
       " ('Right', 'Whale'),\n",
       " ('Captain', 'Peleg'),\n",
       " (',\"', 'said'),\n",
       " ('never', 'mind'),\n",
       " ('!\"', 'cried'),\n",
       " ('no', 'means'),\n",
       " ('each', 'other')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.apply_freq_filter(20)\n",
    "finder.nbest(bigram_measures.pmi, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## &Uuml;bungsaufgaben 4\n",
    "\n",
    "\n",
    "### Aufgabe 1 (Frequenzliste mit Python)\n",
    "In der Vorlesung wurde die Frequenzliste mit der NLTK-Funktion `FreqDist()` sowie nativ mit Python berechnet. \n",
    "\n",
    "### 1a: Berechnen Sie für folgende Tokenliste die Frequenzliste als Python-Dictionary, indem Sie eine entsprechende Funktion definieren (Diese wird für die Tests in 1c benötigt; neben der Berechnung mit if/else gibt es weitere Varianten, etwa mit try/except oder dictionary comprehension)\n",
    "\n",
    "### 1b: Verwenden Sie nun einen Counter der Collections-Library für die Frequenzlisten-Erstellung:\n",
    "`collections import Counter`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['Call', 'me', 'Ishmael', '.', 'Call', 'me', 'Ahab', '.', 'Call', 'him', 'Ahab', '.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c: Führen Sie Efficiency Tests für die verschiedenen Berechnungsarten auf `wahlverwandschaften.txt` durch.  \n",
    "\n",
    "- Verwenden Sie dafür die timeit-Library.\n",
    "- Dazu muss die Frequenzlistberechnung als eine Funktion umgesetzt sein, die eine Tokenliste als Eingabeargument erwartet und eine Frequenzliste ausgibt.\n",
    "- Übergeben Sie diese Funktion an den Timer (`countwords_def_test` im folgenden Beispielcode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['die',\n",
       " 'wahlverwandtschaften',\n",
       " 'ein',\n",
       " 'roman',\n",
       " 'von',\n",
       " 'johann',\n",
       " 'wolfgang',\n",
       " 'von',\n",
       " 'goethe']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "raw_wahlverw = open('wahlverwandschaften.txt').read().lower()\n",
    "wahlverw = word_tokenize(raw_wahlverw)\n",
    "wahlverw[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'die': 0, 'wahlverwandtschaften': 0, 'ein': 0, 'roman': 0, 'von': 0, 'johann': 0, 'wolfgang': 0, 'goethe': 0}\n"
     ]
    }
   ],
   "source": [
    "def countwords_def_test(text):\n",
    "    counts = {t:0 for t in text}    \n",
    "    return counts\n",
    "print(countwords_def_test(wahlverw[0:9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0030081669999990623\n"
     ]
    }
   ],
   "source": [
    "import timeit, functools\n",
    "t = timeit.Timer(functools.partial(countwords_def_test, wahlverw))\n",
    "print(t.timeit(5)) #number of executions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2 (Tokenisierung mit Python und NLTK)\n",
    "Führen Sie auf `wahlverwandschaften.txt` verschiedene Varianten einer Tokenisierung durch. Verwenden Sie: \n",
    "\n",
    "- `split()`\n",
    "- `re.findall()`\n",
    "- `nltk.word_tokenize()`\n",
    "- `nltk.regexp_tokenize()` (siehe https://www.nltk.org/book/ch03.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 3 (gefilterte Frequenzliste mit NLTK)\n",
    "\n",
    "Berechnen Sie  mit NLTK eine Stopwort-gefilterte Frequenzliste auf dem Brown-Korpus und plotten diese."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 4 (Konkordanzen mit Python)\n",
    "\n",
    "Berechnen Sie auf `wahlverwandschaften.txt` eine zeilenweise Konkordanz mit Python für den Suchterm 'geht'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 5 (Bigramme mit Python und NLTK)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5a: Berechnen Sie auf `wahlverwandschaften.txt` eine Bigramm-Liste mit Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5b: Testen Sie verschiedene NLTK-Bigramm-Assoziationsmaße und Frequency-Filter für einen Text ihrer Wahl:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Moby', 'Dick'),\n",
       " ('Sperm', 'Whale'),\n",
       " ('White', 'Whale'),\n",
       " ('Right', 'Whale'),\n",
       " ('Captain', 'Peleg'),\n",
       " (',\"', 'said'),\n",
       " ('never', 'mind'),\n",
       " ('!\"', 'cried'),\n",
       " ('no', 'means'),\n",
       " ('each', 'other')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.apply_freq_filter(20)\n",
    "finder.nbest(bigram_measures.pmi, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 'and'),\n",
       " ('of', 'the'),\n",
       " (\"'\", 's'),\n",
       " ('in', 'the'),\n",
       " (',', 'the'),\n",
       " (';', 'and'),\n",
       " ('to', 'the'),\n",
       " ('.', 'But'),\n",
       " (',', 'that'),\n",
       " ('.', '\"')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.apply_freq_filter(20)\n",
    "finder.nbest(bigram_measures.raw_freq, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
