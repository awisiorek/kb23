#import urllib.request
import sys
import xml.etree.ElementTree as ET 
import spacy 
from nltk import sent_tokenize


def append_text(text, str):
    if not str or str == "":
        return text 
    
    str = str.strip()
    if text == "":
        return str 
    if text[-1] == 'Â¬':
        return text[:-1] + str 
    return text + " " + str 


def gather_text(node, text):
    text = append_text(text, node.text)
    for c in  node:
        text = gather_text(c, text)
    return append_text(text, node.tail)
    
# url = "https://www.deutschestextarchiv.de/book/download_xml/altmann_elementarorganismen_1890"
# with urllib.request.urlopen(url) as f:
#     root = ET.fromstring(f.read())

root = ET.fromstring(sys.stdin.read())    
out = ET.Element('doc')
nlp = spacy.load('de_core_news_sm')
sid = 1 
tid = 1 

ns = {'tei': 'http://www.tei-c.org/ns/1.0'}
text = gather_text(root.find('tei:text', ns), "")

sents = sent_tokenize(text)
for sent in sents: 
    stag = ET.SubElement(out, 's')
    stag.attrib = {'id': f"s-{sid}"}
    sid += 1
    tokens = nlp(sent)
    for token in tokens:
        ttag = ET.SubElement(stag, 'w')
        ttag.text = token.text 
        ttag.attrib = {'pos': token.pos_, 'id': f"w-{tid}"}
        tid += 1

ET.dump(out)
