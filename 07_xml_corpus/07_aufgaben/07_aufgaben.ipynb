{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95b687fe",
   "metadata": {},
   "source": [
    "# Übungsaufgaben 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44bc80b",
   "metadata": {},
   "source": [
    "## Aufgabe 1: Verarbeitung BNC-XML-Korpus\n",
    "\n",
    "Schreiben Sie ein Python-Programm, das \n",
    "\n",
    "- ein Sample des British National Corpus mit Hilfe des NLTK-XML-Korpusreaders (https://www.nltk.org/_modules/nltk/corpus/reader/bnc.html) einliest, \n",
    "\n",
    "- die getaggten Wörter und Sätze (mit `tagged_words()` bzw. `tagged_sents()`) ausgibt,\n",
    "\n",
    "- Bigramme berechnet,\n",
    "\n",
    "- und aus dem XML-Dokumenteninhalt (`<teiHeader>`) die Metadaten mit `xml.etree` extrahiert.\n",
    "\n",
    "Sie können das BNC Sample entweder über NLTK herunterladen: \n",
    "```python\n",
    "nltk.download('bnc')\n",
    "```\n",
    "oder hier manuell herunterladen: https://ota.bodleian.ox.ac.uk/repository/xmlui/handle/20.500.12024/2553"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3098bc6",
   "metadata": {},
   "source": [
    "### Einlesen und NLTK-Korpusmethoden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff5a9c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus.reader.bnc import BNCCorpusReader\n",
    "\n",
    "###nltk.download('bnc')\n",
    "\n",
    "bnc_reader = BNCCorpusReader(root=\"BNC-sample/Texts\", fileids=r'(\\w*)/\\w*\\.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cedb246b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts\n",
      "bncHdr.xml\n",
      "\n",
      "BNC-sample/Texts:\n",
      "news\n",
      "\n",
      "BNC-sample/Texts/news:\n",
      "A1K.xml\n",
      "A3E.xml\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls -R BNC-sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64680416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4202"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bnc_reader.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ca1dbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PUB ROCK / Pint-sized rock ‘ n ’ rollers : Jim White steps back in time to sample the fare at his local By JIM WHITE According to those on the inside track , Raggahouse is the latest fad in clubland . This hybrid mix of reggae and hip hop follows acid jazz , Belgian New Beat and acid swing — the wholly forgettable contribution of Jive Bunny — as the sound to set disco feet tapping . But no matter how often the archives are ransacked for old genres to bastardise , you do n't have to be at\n"
     ]
    }
   ],
   "source": [
    "print(*bnc_reader.words()[:100]) # * = unpacking words-list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "871c486f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ROCK', 'SUBST'), ('/', 'PUN'), ('Pint-sized', 'ADJ'), ('rock', 'SUBST'), ('‘', 'PUQ'), ('n', 'SUBST'), ('’', 'PUQ'), ('rollers', 'SUBST'), (':', 'PUN'), ('Jim', 'SUBST'), ('White', 'SUBST'), ('steps', 'VERB'), ('back', 'ADV'), ('in', 'PREP'), ('time', 'SUBST'), ('to', 'PREP'), ('sample', 'VERB'), ('the', 'ART'), ('fare', 'SUBST')]\n"
     ]
    }
   ],
   "source": [
    "print(bnc_reader.tagged_words()[1:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eec04f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('According', 'VERB'), ('to', 'PREP'), ('those', 'ADJ'), ('on', 'PREP'), ('the', 'ART'), ('inside', 'ADJ'), ('track', 'SUBST'), (',', 'PUN'), ('Raggahouse', 'SUBST'), ('is', 'VERB'), ('the', 'ART'), ('latest', 'ADJ'), ('fad', 'SUBST'), ('in', 'PREP'), ('clubland', 'SUBST'), ('.', 'PUN')]\n"
     ]
    }
   ],
   "source": [
    "print(bnc_reader.tagged_sents()[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75623263",
   "metadata": {},
   "source": [
    "#### Berechnung von Bigrammen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94c52915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('of', 'the'), 0.006663493574488339), (('.', 'The'), 0.004997620180866254), ((',', 'but'), 0.004283674440742504), (('for', 'the'), 0.003093764873869586), (('to', 'be'), 0.003093764873869586), ((',', 'the'), 0.0028557829604950024), (('in', 'the'), 0.0028557829604950024), (('pub', 'rock'), 0.0028557829604950024), (('to', 'the'), 0.0028557829604950024), ((')', '.'), 0.0019038553069966682)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder\n",
    "\n",
    "bigram_measures = BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(bnc_reader.words())\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "\n",
    "print(scored[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d6cce6",
   "metadata": {},
   "source": [
    "### Extraktion von XML-Metadaten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5457a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For access to the complete XML data structure, use the ``xml()`` method.\n",
    "# For access to simple word lists and tagged word lists, use ``words()``, ``sents()``, ``tagged_words()``, and ``tagged_sents()``.\n",
    "# https://www.nltk.org/_modules/nltk/corpus/reader/bnc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d829cf99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xml.etree.ElementTree.Element"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "file = bnc_reader.open('news/A1K.xml')\n",
    "tree = ET.parse(file)\n",
    "\n",
    "#create etree root-Object\n",
    "root = tree.getroot()\n",
    "type(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bfca023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternativ mit NLTK.xml()-Methode:\n",
    "root = bnc_reader.xml('news/A1K.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d888ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "root.text #kein Text direkt unter <bncDoc> Wurzelknoten!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a22bcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element 'teiHeader' at 0x15a518590>\n",
      "<Element 'wtext' at 0x15a684680>\n"
     ]
    }
   ],
   "source": [
    "for el in list(root):\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88718cb4",
   "metadata": {},
   "source": [
    "### itertext() iteriert über ein XML-Knoten und alle Kinderknoten und extrahiert den Text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "494f2f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Independent, electronic edition of 1989-10-02: Listings section. Sample containing about 1842 words from a periodical (domain: arts) \n",
      " Data capture and transcription \n",
      " Oxford University Press \n",
      " \n",
      "BNC XML Edition, December 2006\n",
      " 1842 tokens; 1863 w-units; 94 s-units \n",
      "Distributed under licence by Oxford University Computing Services on behalf of the BNC Consortium.\n",
      " This material is protected by international copyright laws and may not be copied or redistributed in any way. Consult the BNC Web Site at http://www.natcorp.ox.ac.uk for full licencing and distribution conditions.\n",
      "A1K\n",
      " IaList \n",
      "Independent, electronic edition of 1989-10-02: Listings section.\n",
      " \n",
      "Newspaper Publishing plc\n",
      " \n",
      "London\n",
      " \n",
      "1989\n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "for text in list(root[0][0].itertext()): #Inhalt von <fileDesc>\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f43b01",
   "metadata": {},
   "source": [
    "### Iterative Extraktion aus mehreren Korpusfiles mit NLTK.xml():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca486d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Independent, electronic edition of 1989-10-02: Listings section. Sample containing about 1842 words from a periodical (domain: arts) \n",
      " Data capture and transcription \n",
      " Oxford University Press \n",
      " \n",
      "BNC XML Edition, December 2006\n",
      " 1842 tokens; 1863 w-units; 94 s-units \n",
      "Distributed under licence by Oxford University Computing Services on behalf of the BNC Consortium.\n",
      " This material is protected by international copyright laws and may not be copied or redistributed in any way. Consult the BNC Web Site at http://www.natcorp.ox.ac.uk for full licencing and distribution conditions.\n",
      "A1K\n",
      " IaList \n",
      "Independent, electronic edition of 1989-10-02: Listings section.\n",
      " \n",
      "Newspaper Publishing plc\n",
      " \n",
      "London\n",
      " \n",
      "1989\n",
      " \n",
      " \n",
      "  Independent, electronic edition of 1989-10-07: Gardening pages. Sample containing about 1831 words from a periodical (domain: leisure) \n",
      " Data capture and transcription \n",
      " Oxford University Press \n",
      " \n",
      "BNC XML Edition, December 2006\n",
      " 1831 tokens; 1846 w-units; 92 s-units \n",
      "Distributed under licence by Oxford University Computing Services on behalf of the BNC Consortium.\n",
      " This material is protected by international copyright laws and may not be copied or redistributed in any way. Consult the BNC Web Site at http://www.natcorp.ox.ac.uk for full licencing and distribution conditions.\n",
      "A3E\n",
      " IfGard \n",
      "Independent, electronic edition of 1989-10-07: Gardening pages.\n",
      " \n",
      "Newspaper Publishing plc\n",
      " \n",
      "London\n",
      " \n",
      "1989\n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "fileids = ['news/A1K.xml', 'news/A3E.xml']\n",
    "\n",
    "for fileid in fileids:\n",
    "    root = bnc_reader.xml(fileid)\n",
    "    for text in list(root[0][0].itertext()):\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46783823",
   "metadata": {},
   "source": [
    "## Aufgabe 2: xmlpos (Extraktion und Annotation von TEI-XML)\n",
    "Schreiben Sie ein Python-Programm `xmlpos`, das aus einer Korpusdatei\n",
    "den Dokumenteninhalt extrahiert, diesen dann satzweise POS-tagged\n",
    "und eine XML-Datei folgender Form ausgibt:\n",
    "\n",
    "```xml\n",
    "<doc>\n",
    "  <s id=\"s-0001\">\n",
    "    <w id=\"w-0001\" pos=\"DET\">Der</w>\n",
    "\t<w id=\"w-0002\" pos=\"NOUN\">Hase</w>\n",
    "\t...\n",
    "  </s>\n",
    "  <s id=\"s-0002\">\n",
    "  ...\n",
    "</doc>\n",
    "```\n",
    "\n",
    "Anmerkungen:\n",
    "* Verwendenden Sie die [TEI](https://tei-c.org/)-kodierten Korpusdateien des [deutschen Textarchivs](https://www.deutschestextarchiv.de/), z.B:\n",
    "  * Altman 1890: https://www.deutschestextarchiv.de/book/download_xml/altmann_elementarorganismen_1890\n",
    "  * Brandes 1832: https://www.deutschestextarchiv.de/book/download_xml/brandes_naturlehre03_1832\n",
    "\n",
    "\n",
    "> _XML-TEI (Text Encoding Initiative): weit verbreitetes XML-Dokumentenformat für die Kodierung von Textkorpora_    \n",
    "  (Schema mit einheitlichen Elementnamen und Attributen für die editionswissenschaftliche und linguistische Annotation von Texten, u.a. über DTD definiert)\n",
    "\n",
    "> _DTA (Deutsches Textarchiv): historisches deutsches Korpus_ (linguistisch annotiertes Volltextkorpus deutschsprachiger Texte aus der Zeit um 1600 bis 1900)\n",
    "      \n",
    "\n",
    "* Sie können die XML-Dateien auch mit Werkzeugen wie wget oder curl\n",
    "  (man-Pages!)  herunterladen, oder auch Pythons `urllib` verwenden\n",
    "* Sie können `nltk` zur Satzsegmentierung und zum POS-Tagging verwenden; alternativ\n",
    "  dazu können Sie auch _stanza_ (oder _[spacy](https://spacy.io/)_) verwenden\n",
    "* Stellen Sie sicher, dass der tatsächlichen Text aus den Dokumenten extrahiert wird;\n",
    "  betrachten Sie hierzu folgendes (valides) XML-Dokument: `<a><b>1<c>2<d/>3</c></b>4<lb/>5</a>` \n",
    "\n",
    "\n",
    "```xml\n",
    " <a>\n",
    "\t<b>\n",
    "\t\t1\n",
    "\t\t<c>\n",
    "\t\t\t2\n",
    "\t\t\t<d/>\n",
    "\t\t\t3\n",
    "\t\t</c>\n",
    "\t</b>\n",
    "\t4\n",
    "\t<lb/>\n",
    "\t5\n",
    "</a> \n",
    "``` \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07675d6b",
   "metadata": {},
   "source": [
    "#### *weiterführende Informationen:*\n",
    "\n",
    "* [F-Strings](http://cissandbox.bentley.edu/sandbox/wp-content/uploads/2022-02-10-Documentation-on-f-strings-Updated.pdf)\n",
    "* [Spacy](https://spacy.io/)\n",
    "* [DTA](https://www.deutschestextarchiv.de/)\n",
    "* [TEI](https://github.com/TEIC/TEI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b669632d",
   "metadata": {},
   "source": [
    "### Vorgehen:\n",
    "\n",
    "1. XML-Dokument herunterladen (mit `requests`-Library oder `urllib`-Library)\n",
    "2. Text (Inhalt von `<text>`-TEI-Element) mit `etree` aus Datei extrahieren:\n",
    "   - mit XML-Parser über das XML-File iterieren (Namespace des TEI-Wurzelelements berücksichtigen!)\n",
    "   -  Verwendung von Text-Extractor-Klasse (`TreeExtractor`; alternativ mit Funktionsaufruf: `gather_text`) und Hilfsfunktionen (`append_text`)\n",
    "3. Satzsegmentierung(mit `NLTK.sent_tokenize()` und POS-Tagging (hier mit `spacy`)\n",
    "4. Aufbau der neuen XML-Struktur mit `etree` (Satz-Segment- und Wort-POS-Informationen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bb8e7c",
   "metadata": {},
   "source": [
    "#### TEI-XML-Grundstruktur (Altmann-BSP):\n",
    "```xml\n",
    "<TEI xmlns=\"http://www.tei-c.org/ns/1.0\">\n",
    "    <teiHeader>\n",
    "        ...\n",
    "    </teiHeader>\n",
    "    <text>\n",
    "        <front>\n",
    "            <titlePage type=\"halftitle\">\n",
    "                ...\n",
    "            </titlePage>\n",
    "        </front>\n",
    "        <body>\n",
    "            <div n=\"1\">\n",
    "                ...\n",
    "                <p>\n",
    "                    Seitdem von\n",
    "                    <hi rendition=\"#k\">Dujardin</hi>\n",
    "                    die contraktile Substanz oder Sar¬\n",
    "                    <lb/>\n",
    "                    kode entdeckt war, hat dieselbe in Bezug auf die Deutung ihres\n",
    "                    <lb/>\n",
    "                    ...\n",
    "                </p>\n",
    "            </div>\n",
    "        </body>\n",
    "        <back>\n",
    "            ...\n",
    "        </back>\n",
    "    </text>\n",
    "</TEI>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91d5be4",
   "metadata": {},
   "source": [
    "---\n",
    "### 1. append_text\n",
    "\n",
    "- Hilfsfunktion zur Konkatenation von bereits gelesenem Text in der XML-Datei mit neu eingelesenem Text\n",
    "- setzt getrennte Wörter am Zeilenende (`¬</lb>`) zusammen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "601d3fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<abc def>>\n",
      "<<ungelegen>>\n"
     ]
    }
   ],
   "source": [
    "def append_text(text, str):\n",
    "    if not str or str == \"\":\n",
    "        return text \n",
    "    \n",
    "    str = str.strip()\n",
    "    if text == \"\":\n",
    "        return str \n",
    "    if text[-1] == '¬': # Trennerzeichen in XML-File\n",
    "        return text[:-1] + str \n",
    "    return text + \" \" + str \n",
    "\n",
    "print(f'<<{append_text(\"abc\", \"   def \")}>>')\n",
    "print(f'<<{append_text(\"unge¬\", \"legen\")}>>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996e2444",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. TextExtractor\n",
    "\n",
    "- Klasse zur Extraktion von Texts aus XML-Datei\n",
    "- verwendet append_text in rekursiver Iteration über die Kinderknoten   \n",
    "- erwartet root-ET-Objekt (z.B. <text>-Element im TEI-XML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "888a4e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<1 2 3 4 5>>\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET \n",
    "\n",
    "class TextExtractor:\n",
    "    def __init__(self, root):\n",
    "        self.root = root \n",
    "        \n",
    "    def extract(self):\n",
    "        self.text = \"\"\n",
    "        self.extract_rec(self.root) #Iterieren über Kinderknoten mit rekursiver Funktion\n",
    "        return self.text\n",
    "        \n",
    "    def extract_rec(self, node):\n",
    "        self.text = append_text(self.text, node.text)\n",
    "        for c in node:  #Iterieren über Kinderknoten\n",
    "            self.extract_rec(c) #rekursiver Aufruf (für Extraktion des Texts aus Kinder-Knoten)\n",
    "        self.text = append_text(self.text, node.tail) #tail für Elemente vor dem schließenden Tag (im BSP: 4 und 5)\n",
    "        \n",
    "e = TextExtractor(ET.fromstring('<a><b>1<c>2<d/>3</c></b>4<lb/>5</a>'))\n",
    "print(f'<<{e.extract()}>>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d650295",
   "metadata": {},
   "source": [
    "#### Erläuterung: ohne append_text von node.tail (letzte Zeile in extract_rec) wird der Text vor dem schließenden Element nicht extrahiert:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "829d81ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<1 2>>\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET \n",
    "\n",
    "class TextExtractor:\n",
    "    def __init__(self, root):\n",
    "        self.root = root \n",
    "        \n",
    "    def extract(self):\n",
    "        self.text = \"\"\n",
    "        self.extract_rec(self.root)\n",
    "        return self.text\n",
    "        \n",
    "    def extract_rec(self, node):\n",
    "        self.text = append_text(self.text, node.text)\n",
    "        for c in node:\n",
    "            self.extract_rec(c)\n",
    "        #self.text = append_text(self.text, node.tail) #   <<<<<ohne tail: 4 und 5 im BSP werden nicht extrahiert!\n",
    "\n",
    "e = TextExtractor(ET.fromstring('<a><b>1<c>2<d/>3</c></b>4<lb/>5</a>'))\n",
    "print(f'<<{e.extract()}>>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cda990",
   "metadata": {},
   "source": [
    "### *Alternative TextExtractor 1: IterTextExtractor (Verwendung von itertext() in Klasse)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1859306b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<1 2 3 4 5>>\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET \n",
    "\n",
    "class IterTextExtractor:\n",
    "    def __init__(self, root):\n",
    "        self.root = root \n",
    "        \n",
    "    def iter_extract(self):\n",
    "        self.text = \"\"\n",
    "        for c in self.root.itertext():\n",
    "            self.text = append_text(self.text, c)\n",
    "        return self.text\n",
    "\n",
    "e = IterTextExtractor(ET.fromstring('<a><b>1<c>2<d/>3</c></b>4<lb/>5</a>'))\n",
    "print(f'<<{e.iter_extract()}>>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a704a549",
   "metadata": {},
   "source": [
    "### *Alternative Textextraktion 2a: gather_text (ohne Klasse, Verwendung siehe xmlpos.py)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cff6fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<1 2 3 4 5>>\n"
     ]
    }
   ],
   "source": [
    "def gather_text(node, text):\n",
    "    text = append_text(text, node.text)\n",
    "    for c in node: #Iterieren über Kinder-Knoten\n",
    "        text = gather_text(c, text) #rekursiver Aufruf\n",
    "    #return text\n",
    "    return append_text(text, node.tail)\n",
    "\n",
    "root = ET.fromstring('<a><b>1<c>2<d/>3</c></b>4<lb/>5</a>')\n",
    "text = gather_text(root, \"\")\n",
    "print(f'<<{text}>>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f21435",
   "metadata": {},
   "source": [
    "### *Alternative 2b: gather_text_alt (ohne Klasse, ohne Aufruf mit Initialsstring)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5fa038b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<1 2 3 4 5>>\n"
     ]
    }
   ],
   "source": [
    "def gather_text_alt(node):\n",
    "    return gather_text_rec(node, \"\")\n",
    "\n",
    "def gather_text_rec(node, text):\n",
    "    text = append_text(text, node.text)\n",
    "    for c in  node:\n",
    "        text = gather_text_rec(c, text)\n",
    "    return append_text(text, node.tail)\n",
    "    \n",
    "root = ET.fromstring('<a><b>1<c>2<d/>3</c></b>4<lb/>5</a>')\n",
    "text = gather_text_alt(root)\n",
    "print(f'<<{text}>>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8907e5",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Download der XML-Dateien und Verwendung der TextExtractor-Klasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44bc398e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zu sichern. Das Bewusstsein, dass uns hier die Grundprobleme der Biologie berühren, wird es hoffen\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET \n",
    "\n",
    "import urllib.request\n",
    "url = \"https://www.deutschestextarchiv.de/book/download_xml/altmann_elementarorganismen_1890\"\n",
    "# url = \"https://www.deutschestextarchiv.de/book/download_xml/brandes_naturlehre03_1832\"\n",
    "\n",
    "\n",
    "with urllib.request.urlopen(url) as f:\n",
    "    root = ET.fromstring(f.read())\n",
    "\n",
    "# TEI-Namespace (Namespace als Präfix der Elementnamen, z.B. http://www.tei-c.org/ns/1.0:element)\n",
    "ns = {'tei': 'http://www.tei-c.org/ns/1.0'} #Namespace-Dictionary mit Abkürzungen\n",
    "\n",
    "# Extraktion mit <tei:text> als Wurzelknoten (d.h. ohne Metadaten in <teiHeader>):\n",
    "e = TextExtractor(root.find('tei:text', ns))\n",
    "text = e.extract()\n",
    "print(text[1002:1100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2cf341",
   "metadata": {},
   "source": [
    "### 4. Download des [Spacy](https://spacy.io) Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f980e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54e6675",
   "metadata": {},
   "source": [
    "### 5. Importe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9a70132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#!{sys.executable} -m pip install --upgrade pip spacy\n",
    "import spacy\n",
    "#!{sys.executable} -m pip install --upgrade pip nltk\n",
    "from nltk import sent_tokenize\n",
    "import xml.dom.minidom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dfc31d",
   "metadata": {},
   "source": [
    "### 6. POS-Tagging mit spaCy und Aufbau des XML-Baums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23941535",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" ?>\n",
      "<doc>\n",
      "\t<s id=\"s-00001\">\n",
      "\t\t<w id=\"w-00001\" pos=\"DET\">DIE</w>\n",
      "\t\t<w id=\"w-00002\" pos=\"NOUN\">ELEMENTARORGANISMEN</w>\n",
      "\t\t<w id=\"w-00003\" pos=\"PROPN\">BEZIEHUNGEN</w>\n",
      "\t\t<w id=\"w-00004\" pos=\"ADP\">ZU</w>\n",
      "\t\t<w id=\"w-00005\" pos=\"PROPN\">DEN</w>\n",
      "\t\t<w id=\"w-00006\" pos=\"PROPN\">ZELLEN</w>\n",
      "\t\t<w id=\"w-00007\" pos=\"ADP\">VON</w>\n",
      "\t\t<w id=\"w-00008\" pos=\"SPACE\"> </w>\n",
      "\t\t<w id=\"w-00009\" pos=\"PROPN\">RICHARD</w>\n",
      "\t\t<w id=\"w-00010\" pos=\"PROPN\">ALTMANN</w>\n",
      "\t\t<w id=\"w-00011\" pos=\"PROPN\">MIT</w>\n",
      "\t\t<w id=\"w-00012\" pos=\"PROPN\">ZWEI</w>\n",
      "\t\t<w id=\"w-00013\" pos=\"PROPN\">ABBILDUNGEN</w>\n",
      "\t\t<w id=\"w-00014\" pos=\"ADP\">IM</w>\n",
      "\t\t<w id=\"w-00015\" pos=\"PROPN\">TEXT</w>\n",
      "\t\t<w id=\"w-00016\" pos=\"CCONJ\">UND</w>\n",
      "\t\t<w id=\"w-00017\" pos=\"PROPN\">XXI</w>\n",
      "\t\t<w id=\"w-00018\" pos=\"PROPN\">TAFELN</w>\n",
      "\t\t<w id=\"w-00019\" pos=\"PUNCT\">.</w>\n",
      "\t</s>\n",
      "\t<s id=\"s-00002\">\n",
      "\t\t<w id=\"w-00020\" pos=\"PROPN\">LEIPZIG</w>\n",
      "\t\t<w id=\"w-00021\" pos=\"PUNCT\">,</w>\n",
      "\t\t<w id=\"w-00022\" pos=\"PROPN\">VERLAG</w>\n",
      "\t\t<w id=\"w-00023\" pos=\"PROPN\">VON</w>\n",
      "\t\t<w id=\"w-00024\" pos=\"PROPN\">VEIT</w>\n",
      "\t\t<w id=\"w-00025\" pos=\"CCONJ\">&amp;</w>\n",
      "\t\t<w id=\"w-00026\" pos=\"PROPN\">COMP</w>\n",
      "\t\t<w id=\"w-00027\" pos=\"PUNCT\">.</w>\n",
      "\t</s>\n",
      "\t<s id=\"s-00003\">\n",
      "\t\t<w id=\"w-00028\" pos=\"NUM\">1890.</w>\n",
      "\t</s>\n",
      "\t<s id=\"s-00004\">\n",
      "\t\t<w id=\"w-00029\" pos=\"DET\">DIE</w>\n",
      "\t\t<w id=\"w-00030\" pos=\"NOUN\">ELEMENTARORGANISMEN</w>\n",
      "\t\t<w id=\"w-00031\" pos=\"PROPN\">BEZIEHUNGEN</w>\n",
      "\t\t<w id=\"w-00032\" pos=\"ADP\">ZU</w>\n",
      "\t\t<w id=\"w-00033\" pos=\"PROPN\">DEN</w>\n",
      "\t\t<w id=\"w-00034\" pos=\"PROPN\">ZELLEN</w>\n",
      "\t\t<w id=\"w-00035\" pos=\"PUNCT\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('de_core_news_sm')\n",
    "out = ET.Element('doc') #für Erzeugung XML-File\n",
    "sid = 1 # sentence id\n",
    "wid = 1 # word id\n",
    "\n",
    "#Satzsegmentierung mit NLTK-Methode:\n",
    "sents = sent_tokenize(text)\n",
    "\n",
    "#POS-Tagging mit spaCy und Erzeugung XML-File:\n",
    "for sent in sents:\n",
    "    stag = ET.SubElement(out, 's') #Erzeugung von s-Element\n",
    "    stag.attrib = {'id': f's-{sid:05d}'}\n",
    "    sid += 1\n",
    "    tokens = nlp(sent) #Analyse mit spaCy\n",
    "    for token in tokens: #Erzeugen von w-Elementen (pro Satz)\n",
    "        wtag = ET.SubElement(stag, 'w')\n",
    "        wtag.text = token.text\n",
    "        wtag.attrib = {'pos': token.pos_, 'id': f'w-{wid:05d}'}\n",
    "        wid += 1\n",
    "\n",
    "dom = xml.dom.minidom.parseString(ET.tostring(out))\n",
    "print(dom.toprettyxml()[:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6617bce8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Usage von xmlpos.py:\n",
    "\n",
    "#### Einlesen aus XML-Datei, Tagging und Transformation mit xmlpos.py, Ausgabe in neue XML-Datei:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "805a35f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat altmann_elementarorganismen_1890.TEI-P5.xml | python3 xmlpos.py > altmann_elementarorganismen_1890_spacy.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e28af6e",
   "metadata": {},
   "source": [
    "#### Formatierte Ausgabe XML auf Kommandozeile mit xmllint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "963db56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\"?>\n",
      "<doc>\n",
      "  <s id=\"s-1\">\n",
      "    <w pos=\"DET\" id=\"w-1\">DIE</w>\n",
      "    <w pos=\"SPACE\" id=\"w-2\"> </w>\n",
      "    <w pos=\"NOUN\" id=\"w-3\">ELEMENTARORGANISMEN</w>\n",
      "    <w pos=\"CCONJ\" id=\"w-4\">UND</w>\n",
      "    <w pos=\"PROPN\" id=\"w-5\">IHRE</w>\n",
      "    <w pos=\"SPACE\" id=\"w-6\"> </w>\n",
      "    <w pos=\"PROPN\" id=\"w-7\">BEZIEHUNGEN</w>\n",
      "    <w pos=\"NOUN\" id=\"w-8\">ZU</w>\n",
      "    <w pos=\"PROPN\" id=\"w-9\">DEN</w>\n",
      "    <w pos=\"PROPN\" id=\"w-10\">ZELLEN</w>\n",
      "    <w pos=\"PUNCT\" id=\"w-11\">.</w>\n",
      "  </s>\n",
      "  <s id=\"s-2\">\n",
      "    <w pos=\"ADP\" id=\"w-12\">VON</w>\n",
      "    <w pos=\"SPACE\" id=\"w-13\">  </w>\n",
      "    <w pos=\"X\" id=\"w-14\">RICHARD</w>\n",
      "    <w pos=\"PROPN\" id=\"w-15\">ALTMANN</w>\n",
      "    <w pos=\"PUNCT\" id=\"w-16\">.</w>\n",
      "  </s>\n",
      "  <s id=\"s-3\">\n",
      "    <w pos=\"ADP\" id=\"w-17\">MIT</w>\n",
      "    <w pos=\"ADV\" id=\"w-18\">ZWEI</w>\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "xmllint --format altmann_elementarorganismen_1890_spacy.xml | head -25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7c8818a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  <s id=\"s-12\">\n",
      "    <w pos=\"NOUN\" id=\"w-82\">Vorbemerkung</w>\n",
      "    <w pos=\"PUNCT\" id=\"w-83\">.</w>\n",
      "  </s>\n",
      "  <s id=\"s-13\">\n",
      "    <w pos=\"DET\" id=\"w-84\">Die</w>\n",
      "    <w pos=\"ADJ\" id=\"w-85\">nachfolgenden</w>\n",
      "    <w pos=\"NOUN\" id=\"w-86\">Capitel</w>\n",
      "    <w pos=\"VERB\" id=\"w-87\">enthalten</w>\n",
      "    <w pos=\"ADP\" id=\"w-88\">im</w>\n",
      "    <w pos=\"NOUN\" id=\"w-89\">Wesentlichen</w>\n",
      "    <w pos=\"DET\" id=\"w-90\">eine</w>\n",
      "    <w pos=\"NOUN\" id=\"w-91\">theils</w>\n",
      "    <w pos=\"VERB\" id=\"w-92\">erweiterte</w>\n",
      "    <w pos=\"PUNCT\" id=\"w-93\">,</w>\n",
      "    <w pos=\"ADV\" id=\"w-94\">theils</w>\n",
      "    <w pos=\"ADJ\" id=\"w-95\">verk&#xFC;rzte</w>\n",
      "    <w pos=\"NOUN\" id=\"w-96\">Zusammenstellung</w>\n",
      "    <w pos=\"DET\" id=\"w-97\">derjenigen</w>\n",
      "    <w pos=\"NOUN\" id=\"w-98\">Abhandlungen</w>\n",
      "    <w pos=\"PUNCT\" id=\"w-99\">,</w>\n",
      "    <w pos=\"PRON\" id=\"w-100\">welche</w>\n",
      "    <w pos=\"ADV\" id=\"w-101\">bisher</w>\n",
      "    <w pos=\"ADP\" id=\"w-102\">von</w>\n",
      "    <w pos=\"PRON\" id=\"w-103\">mir</w>\n",
      "    <w pos=\"ADP\" id=\"w-104\">&#xFC;ber</w>\n",
      "    <w pos=\"DET\" id=\"w-105\">die</w>\n",
      "    <w pos=\"NOUN\" id=\"w-106\">Zellengranula</w>\n",
      "    <w pos=\"VERB\" id=\"w-107\">ver&#xF6;ffentlicht</w>\n",
      "    <w pos=\"AUX\" id=\"w-108\">worden</w>\n",
      "    <w pos=\"AUX\" id=\"w-109\">sind</w>\n",
      "    <w pos=\"PUNCT\" id=\"w-110\">.</w>\n",
      "  </s>\n",
      "  <s id=\"s-14\">\n",
      "    <w pos=\"SCONJ\" id=\"w-111\">Indem</w>\n",
      "    <w pos=\"ADV\" id=\"w-112\">hierzu</w>\n",
      "    <w pos=\"DET\" id=\"w-113\">die</w>\n",
      "    <w pos=\"NOUN\" id=\"w-114\">Beschreibung</w>\n",
      "    <w pos=\"DET\" id=\"w-115\">der</w>\n",
      "    <w pos=\"NOUN\" id=\"w-116\">Methoden</w>\n",
      "    <w pos=\"CCONJ\" id=\"w-117\">und</w>\n",
      "    <w pos=\"DET\" id=\"w-118\">die</w>\n",
      "    <w pos=\"ADJ\" id=\"w-119\">erl&#xE4;uternden</w>\n",
      "    <w pos=\"NOUN\" id=\"w-120\">Abbildungen</w>\n",
      "    <w pos=\"VERB\" id=\"w-121\">kommen</w>\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "xmllint --format altmann_elementarorganismen_1890_spacy.xml | sed -n '106,150p'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6108b8",
   "metadata": {},
   "source": [
    "#### Alternatives Herunterladen der XML-Datei mit curl:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7386ee72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r\n",
      " 22  385k   22 90112    0     0  49558      0  0:00:07  0:00:01  0:00:06 49539\r\n",
      "100  385k  100  385k    0     0   202k      0  0:00:01  0:00:01 --:--:--  202k\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl https://www.deutschestextarchiv.de/book/download_xml/altmann_elementarorganismen_1890 | python3 xmlpos.py > altmann_elementarorganismen_1890_spacy.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39224519",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Aufgabe 2: POS-Tagging mit stanza\n",
    "\n",
    "- Abschließend wird hier noch eine Variante gezeigt, die stanza statt spaCy zum POS-Tagging verwendet\n",
    "- auch zur Satzsegmentierung wird hier stanza verwendet\n",
    "\n",
    "\n",
    "- MWT (Multi-Word Token Expansion) in Pipeline führt zu Abweichungen vom Originaltext, wenn man die über die words iteriert und diese ausgibt\n",
    "  - da z.B. *zum* zu *zu* *dem* transformiert wird\n",
    "- stattdessen muss über die tokens iteriert werden und POS-Infos aus den words eines token extrahiert werden\n",
    "- vgl. https://stanfordnlp.github.io/stanza/mwt.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eb7014",
   "metadata": {},
   "source": [
    "#### xmlpos_stanza.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d7ffec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import xml.etree.ElementTree as ET \n",
    "import stanza\n",
    "\n",
    "\n",
    "def append_text(text, str):\n",
    "    if not str or str == \"\":\n",
    "        return text \n",
    "    \n",
    "    str = str.strip()\n",
    "    if text == \"\":\n",
    "        return str \n",
    "    if text[-1] == '¬':\n",
    "        return text[:-1] + str \n",
    "    return text + \" \" + str \n",
    "\n",
    "\n",
    "def gather_text(node, text):\n",
    "    text = append_text(text, node.text)\n",
    "    for c in  node:\n",
    "        text = gather_text(c, text)\n",
    "    return append_text(text, node.tail)\n",
    "    \n",
    "\n",
    "root = ET.fromstring(sys.stdin.read())    \n",
    "out = ET.Element('doc')\n",
    "nlp = stanza.Pipeline(lang='de', processors='tokenize, pos', download_method=None) #stanza-Pipeline\n",
    "sid = 1 \n",
    "tid = 1\n",
    "text = gather_text(root, \"\")\n",
    "\n",
    "for t in root.iter('{http://www.tei-c.org/ns/1.0}text'):\n",
    "    text = gather_text(t, \"\")\n",
    "    \n",
    "    doc = nlp(text)  #POS-Annotation mit stanza\n",
    "    sents = doc.sentences  #Tokenisierung: hier mit stanza statt NLTK.sent_tokenize\n",
    "    for sent in sents: \n",
    "        stag = ET.SubElement(out, 's')\n",
    "        stag.attrib = {'id': f\"s-{sid}\"}\n",
    "        sid += 1\n",
    "        \n",
    "        tokens = sent.tokens #stanza-Methode .tokens (statt .words, wegen MWT)\n",
    "        for token in tokens:\n",
    "            ttag = ET.SubElement(stag, 'w')\n",
    "            ttag.text = token.text\n",
    "            word_upos = \"+\".join([word.upos for word in token.words]) #join der durch MWT von stanza getrennt analysierten word-POS-tags\n",
    "            ttag.attrib = {'pos': word_upos, 'id': f\"w-{tid}\"}  #stanza\n",
    "            tid += 1 \n",
    "ET.dump(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d60ccf",
   "metadata": {},
   "source": [
    "#### Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6a265db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 12:08:49 WARNING: Language de package default expects mwt, which has been added\n",
      "2023-06-29 12:08:49 INFO: Loading these models for language: de (German):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsd     |\n",
      "| mwt       | gsd     |\n",
      "| pos       | gsd     |\n",
      "=======================\n",
      "\n",
      "2023-06-29 12:08:49 INFO: Using device: cpu\n",
      "2023-06-29 12:08:49 INFO: Loading: tokenize\n",
      "2023-06-29 12:08:49 INFO: Loading: mwt\n",
      "2023-06-29 12:08:49 INFO: Loading: pos\n",
      "2023-06-29 12:08:49 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat altmann_elementarorganismen_1890.TEI-P5.xml | python3 xmlpos_stanza.py > altmann_elementarorganismen_1890_stanza.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "98480daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  <s id=\"s-10\">\n",
      "    <w pos=\"NOUN\" id=\"w-75\">Vorbemerkung</w>\n",
      "    <w pos=\"PUNCT\" id=\"w-76\">.</w>\n",
      "  </s>\n",
      "  <s id=\"s-11\">\n",
      "    <w pos=\"DET\" id=\"w-77\">Die</w>\n",
      "    <w pos=\"ADJ\" id=\"w-78\">nachfolgenden</w>\n",
      "    <w pos=\"NOUN\" id=\"w-79\">Capitel</w>\n",
      "    <w pos=\"VERB\" id=\"w-80\">enthalten</w>\n",
      "    <w pos=\"ADP+DET\" id=\"w-81\">im</w>\n",
      "    <w pos=\"NOUN\" id=\"w-82\">Wesentlichen</w>\n",
      "    <w pos=\"DET\" id=\"w-83\">eine</w>\n",
      "    <w pos=\"ADV\" id=\"w-84\">theils</w>\n",
      "    <w pos=\"ADJ\" id=\"w-85\">erweiterte</w>\n",
      "    <w pos=\"PUNCT\" id=\"w-86\">,</w>\n",
      "    <w pos=\"ADV\" id=\"w-87\">theils</w>\n",
      "    <w pos=\"ADJ\" id=\"w-88\">verk&#xFC;rzte</w>\n",
      "    <w pos=\"NOUN\" id=\"w-89\">Zusammenstellung</w>\n",
      "    <w pos=\"PRON\" id=\"w-90\">derjenigen</w>\n",
      "    <w pos=\"NOUN\" id=\"w-91\">Abhandlungen</w>\n",
      "    <w pos=\"PUNCT\" id=\"w-92\">,</w>\n",
      "    <w pos=\"PRON\" id=\"w-93\">welche</w>\n",
      "    <w pos=\"ADV\" id=\"w-94\">bisher</w>\n",
      "    <w pos=\"ADP\" id=\"w-95\">von</w>\n",
      "    <w pos=\"PRON\" id=\"w-96\">mir</w>\n",
      "    <w pos=\"ADP\" id=\"w-97\">&#xFC;ber</w>\n",
      "    <w pos=\"DET\" id=\"w-98\">die</w>\n",
      "    <w pos=\"NOUN\" id=\"w-99\">Zellengranula</w>\n",
      "    <w pos=\"VERB\" id=\"w-100\">ver&#xF6;ffentlicht</w>\n",
      "    <w pos=\"AUX\" id=\"w-101\">worden</w>\n",
      "    <w pos=\"AUX\" id=\"w-102\">sind</w>\n",
      "    <w pos=\"PUNCT\" id=\"w-103\">.</w>\n",
      "  </s>\n",
      "  <s id=\"s-12\">\n",
      "    <w pos=\"SCONJ\" id=\"w-104\">Indem</w>\n",
      "    <w pos=\"ADV\" id=\"w-105\">hierzu</w>\n",
      "    <w pos=\"DET\" id=\"w-106\">die</w>\n",
      "    <w pos=\"NOUN\" id=\"w-107\">Beschreibung</w>\n",
      "    <w pos=\"DET\" id=\"w-108\">der</w>\n",
      "    <w pos=\"NOUN\" id=\"w-109\">Methoden</w>\n",
      "    <w pos=\"CCONJ\" id=\"w-110\">und</w>\n",
      "    <w pos=\"DET\" id=\"w-111\">die</w>\n",
      "    <w pos=\"ADJ\" id=\"w-112\">erl&#xE4;uternden</w>\n",
      "    <w pos=\"NOUN\" id=\"w-113\">Abbildungen</w>\n",
      "    <w pos=\"VERB\" id=\"w-114\">kommen</w>\n",
      "    <w pos=\"PUNCT\" id=\"w-115\">,</w>\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "xmllint --format altmann_elementarorganismen_1890_stanza.xml | sed -n '95,140p'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
